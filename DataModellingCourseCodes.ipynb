{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22286325-09d0-47b9-a81c-eb63c8fa2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impoting nessesary libraries/\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfb11e-d44f-4d07-8eb4-2da08abcdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indentify database, input and output variables. Inputs are 'R1','R2','R3' are reagents used in experiments and 'T' is time. Outputs are Recovery 'Act_Rec' and 'Grade' as grade of products as a results of experiments.\n",
    "\n",
    "df=pd.read_excel('Manuscript data.xlsx', sheet_name='DatabaseNewData', header=0) #calling data from excel\n",
    "df #calling all the excel columns \n",
    "df.describe() #decribtice statistic of data\n",
    "r1=df[['R1']] #input 1\n",
    "r2=df[['R2']] #input 2\n",
    "r3=df[['R3']] #input 3\n",
    "t=df[['Time']] #input 4\n",
    "rec=df[['Act_Rec']] #output 1\n",
    "grd=df[['Grade']] #output 2\n",
    "inp=df[['R1', 'R2', 'R3', 'Time']] #inputs were merged and identified as an array\n",
    "\n",
    "#outputs were identified seperately as recovery 'outp_r' and 'outp_g'\n",
    "outp_r=df[['Act_Rec']]\n",
    "outp_g=df[['Grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5994d-27ce-4bff-b607-62e6b8f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are two models for recovery and grade\n",
    "\n",
    "#first model is for recovery\n",
    "model_l_r=linear_model.LinearRegression() #calling linear regression model\n",
    "model_l_r.fit(inp,outp_r) #data fitting with inp and out_r\n",
    "model_l_r.score(inp,outp_r) #calling RSQ value of model\n",
    "\n",
    "#after build a model, it is time to collect model predictions using same inputs\n",
    "est_l_r=model_l_r.predict(inp) #identification of model predictions\n",
    "model_l_r.intercept_ #intercpet value of model\n",
    "model_l_r.coef_ #coefficients values of parameters (inputs)\n",
    "\n",
    "print('MAE_L_R:',mean_absolute_error(outp_r,est_l_r)) #priting MAE values of model using actual outputs and model estimations \n",
    "print('MSE_L_R:',mean_squared_error(outp_r,est_l_r)) #priting MSE values of model using actual outputs and model estimations \n",
    "print('r2_L_R:',r2_score(outp_r,est_l_r)) #priting RSQ values of model using actual outputs and model estimations \n",
    " \n",
    "#second model is for grade and procedure is exacly same, only difference is that actual outups are grade in this model, not recoveries\n",
    "model_l_g=linear_model.LinearRegression()\n",
    "model_l_g.fit(inp,outp_g)\n",
    "model_l_g.score(inp,outp_g)\n",
    "est_l_g=model_l_g.predict(inp)\n",
    "model_l_g.intercept_\n",
    "model_l_g.coef_\n",
    "est_l_g=model_l_g.predict(inp)\n",
    "print('MAE_L_R:',mean_absolute_error(outp_g,est_l_g))\n",
    "print('MSE_L_R:',mean_squared_error(outp_g,est_l_g))\n",
    "print('r2_L_G:',r2_score(outp_g,est_l_g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e3ceb-9788-4982-a965-c5aa2a3da05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONLINEAR REGRESSION\n",
    "\n",
    "#FIRSTLY MODEL WILL BE BUILD FOR RECOVERY AND THAN SAME PROCEDURE WILL BE FOLLOWED FOR GRADE \n",
    "poly_converter = PolynomialFeatures() #structure of nonlinear regression is different, new array should be shaped using same data thats why PolynominalFeatures() function was called\n",
    "poly_features1 = poly_converter.fit_transform(inp) #pol_converter function reshapred the array and make it proper for nonlinear regression\n",
    "poly_features1.shape #shows the size of the new array, normally array of us \"inp\" is [190, 4], the new collumns were added in order to get quantratic equations \n",
    "model_nl_r=linear_model.LinearRegression() #Now we can run linear regression with this new trnasformed array and build a new linear regression model\n",
    "model_nl_r.fit(poly_features1,outp_r) #New array and actual oupts were fitted by new model\n",
    "est_nl_r=model_nl_r.predict(poly_features1) #collection of model predictions\n",
    "poly_converter.degree #degree of functions\n",
    "model_nl_r.score(poly_features1, outp_r) #RSQ of new model\n",
    "model_nl_r.intercept_ #Intercept value of model\n",
    "model_nl_r.coef_ #Coefficient values of functions, since there are four parameters and it is quantratic equations, number of coeeficients are quite high, but they are important to understand contribition of the variabiles\n",
    "coef_r=model_nl_r.coef_\n",
    "print('MAE_NL_R:',mean_absolute_error(outp_r,est_nl_r)) #MAE values of model\n",
    "print('MSE_NL_R:',mean_squared_error(outp_r,est_nl_r)) #MSE values of model\n",
    "print('r2_NL_R:',r2_score(outp_r,est_nl_r)) #RSQ values of model\n",
    "\n",
    "#Same procedure as previous model, this time ouput is grade\n",
    "model_nl_g=linear_model.LinearRegression()\n",
    "model_nl_g.fit(poly_features1,outp_g)\n",
    "est_nl_g=model_nl_g.predict(poly_features1)\n",
    "poly_converter.degree\n",
    "model_nl_g.score(poly_features1, outp_g)\n",
    "model_nl_g.intercept_\n",
    "model_nl_g.coef_\n",
    "print('MAE_NL_G:',mean_absolute_error(outp_g,est_nl_g))\n",
    "print('MSE_NL_G:',mean_squared_error(outp_g,est_nl_g))\n",
    "print('r2_NL_G:',r2_score(outp_g,est_nl_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a37d65-a630-4b6d-8637-c45cea2cbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST (RF) MODELS\n",
    "\n",
    "#In (RF), data should be splitted as training and tests, each splitted data should be identified \n",
    "#inp_train is slpitted input data for train, #inp_tests is slpitted input data for tests, \n",
    "#outp_r__train is slpitted output recovery data for train, #outp_r__test is slpitted output recovery data for test, \n",
    "inp_train, inp_test, outp_r_train, outp_r_test = train_test_split(inp, outp_r, test_size=0.20, random_state=55)  #function splitted database randomly, size were decrived in phrahtase\n",
    "#after randomized splitted we can call the inputs and outputs\n",
    "inp_train \n",
    "inp_test\n",
    "\n",
    "outp_r_train\n",
    "outp_r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b776c-2868-4dbb-92b1-ae6de30dc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here trains datas are spliited to 5 and each time they are shuffled and for cross validation. n_splits can be changed depends on the number of data\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "r_f_m_r = RandomForestRegressor() #RF regression algorithm is called\n",
    "score_r_f_m_r=cross_val_score(r_f_m_r, inp_train, outp_r_train, cv=cv) #scores of cross validation of training data\n",
    "model_r_f_m_r=r_f_m_r.fit(inp_train, outp_r_train)  #RF models transfer to mode_r_f_m_r while fitting train data of input and output for recovery\n",
    "score_r_f_m_r #RSQ of RF model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64c138-80c5-4cbf-bb85-3d5c9cc6c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of prediction of RFM for recovery\n",
    "\n",
    "predict_r_test = r_f_m_r.predict(inp_test)\n",
    "predict_r_train = r_f_m_r.predict(inp_train)\n",
    "predict_r_all = r_f_m_r.predict(inp)\n",
    "\n",
    "#printing MAE, MSE and R2 VALUES\n",
    "print('Test 1 R2:', r2_score(outp_r_test, predict_r_test))\n",
    "print('Train 1 R2:', r2_score(outp_r_train, predict_r_train))\n",
    "print('All 1 R2:', r2_score(outp_r, predict_r_all))\n",
    "print('test 1 mae:',mean_absolute_error(outp_r_test, predict_r_test))\n",
    "print('train 1 mae:',mean_absolute_error(outp_r_train, predict_r_train))\n",
    "print('all 1 mae:',mean_absolute_error(outp_r, predict_r_all))\n",
    "print('test 1 mse:',mean_squared_error(outp_r_test, predict_r_test))\n",
    "print('train 1 mse:',mean_squared_error(outp_r_train, predict_r_train))\n",
    "print('all 1 mse:',mean_squared_error(outp_r, predict_r_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc96ba-2aae-4e06-8603-7ac58483015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same prodecure for grade values \n",
    "\n",
    "inp_train, inp_test, outp_g_train, outp_g_test = train_test_split(inp, outp_g, test_size=0.20, random_state=55)\n",
    "inp_train\n",
    "inp_test\n",
    "\n",
    "outp_g_train\n",
    "outp_g_test\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "r_f_m_g = RandomForestRegressor()\n",
    "score_r_f_m_g=cross_val_score(r_f_m_g, inp_train, outp_g_train, cv=cv)\n",
    "model_r_f_m_g=r_f_m_g.fit(inp_train, outp_g_train)\n",
    "score_r_f_m_g\n",
    "\n",
    "predict_g_test = r_f_m_g.predict(inp_test)\n",
    "predict_g_train = r_f_m_g.predict(inp_train)\n",
    "predict_g_all = r_f_m_g.predict(inp)\n",
    "\n",
    "print('Test 1 R2:', r2_score(outp_g_test, predict_g_test))\n",
    "print('Train 1 R2:', r2_score(outp_g_train, predict_g_train))\n",
    "print('All 1 R2:', r2_score(outp_g, predict_g_all))\n",
    "print('test 1 mae:',mean_absolute_error(outp_g_test, predict_g_test))\n",
    "print('train 1 mae:',mean_absolute_error(outp_g_train, predict_g_train))\n",
    "print('all 1 mae:',mean_absolute_error(outp_g, predict_g_all))\n",
    "print('test 1 mse:',mean_squared_error(outp_g_test, predict_g_test))\n",
    "print('train 1 mse:',mean_squared_error(outp_g_train, predict_g_train))\n",
    "print('all 1 mse:',mean_squared_error(outp_g, predict_g_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb3caf-6f49-4b1d-8c69-96a29ca38db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unseen data should be run into model to see performance of the models with unseen data\n",
    "#external excel file must be introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b9e45-abdf-4118-8c46-10e62a78832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indentify database, input and output variables. Inputs are 'R1','R2','R3' are reagents used in experiments and 'T' is time. Outputs are Recovery 'Act_Rec' and 'Grade' as grade of products as a results of experiments.\n",
    "\n",
    "df2=pd.read_excel('Unseendata.xlsx', sheet_name='Unseendata', header=0) #calling data from excel\n",
    "df2 #calling all the excel columns \n",
    "ur1=df2[['R1']] #input 1\n",
    "ur2=df2[['R2']] #input 2\n",
    "ur3=df2[['R3']] #input 3\n",
    "ut=df2[['T']] #input 4\n",
    "urec=df2[['Act_Rec']] #output 1\n",
    "ugrd=df2[['Grade']] #output 2\n",
    "uinp=df2[['R1', 'R2', 'R3', 'T']] #inputs were merged and identified as an array\n",
    "\n",
    "#outputs were identified seperately as recovery 'outp_r' and 'outp_g'\n",
    "uoutp_r=df2[['Act_Rec']]\n",
    "uoutp_g=df2[['Grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec564d0-1330-422f-8483-04a5aab10b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_l_u_r=model_l_r.predict(uinp) #identification of model predictions\n",
    "est_l_u_r\n",
    "\n",
    "print('MAE_L_R:',mean_absolute_error(uoutp_r,est_l_u_r)) #priting MAE values of model using actual outputs and model estimations \n",
    "print('MSE_L_R:',mean_squared_error(uoutp_r,est_l_u_r)) #priting MSE values of model using actual outputs and model estimations \n",
    "print('r2_L_R:',r2_score(uoutp_r,est_l_u_r)) #priting RSQ values of model using actual outputs and model estimations \n",
    "\n",
    "\n",
    "est_l_u_g=model_l_g.predict(uinp) #identification of model predictions\n",
    "est_l_u_g\n",
    "\n",
    "print('MAE_L_R:',mean_absolute_error(uoutp_g,est_l_u_g)) #priting MAE values of model using actual outputs and model estimations \n",
    "print('MSE_L_R:',mean_squared_error(uoutp_g,est_l_u_g)) #priting MSE values of model using actual outputs and model estimations \n",
    "print('r2_L_R:',r2_score(uoutp_g,est_l_u_g)) #priting RSQ values of model using actual outputs and model estimations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4474ec-3f74-4758-a669-572f7e99f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features2 = poly_converter.fit_transform(uinp) #pol_converter function reshapred the array and make it proper for nonlinear regression\n",
    "poly_features2.shape #shows the size of the new array, normally array of us \"inp\" is [190, 4], the new collumns were added in order to get quantratic equations \n",
    "u_model_nl_r=linear_model.LinearRegression() #Now we can run linear regression with this new trnasformed array and build a new linear regression model\n",
    "u_model_nl_r.fit(poly_features2,uoutp_r) #New array and actual oupts were fitted by new model\n",
    "u_est_nl_r=model_nl_r.predict(poly_features2) #collection of model predictions\n",
    "\n",
    "u_est_nl_r\n",
    "print('MAE_NL_R:',mean_absolute_error(outp_r,est_nl_r)) #MAE values of model\n",
    "print('MSE_NL_R:',mean_squared_error(outp_r,est_nl_r)) #MSE values of model\n",
    "print('r2_NL_R:',r2_score(outp_r,est_nl_r)) #RSQ values of model\n",
    "\n",
    "\n",
    "\n",
    "u_model_nl_g=linear_model.LinearRegression() #Now we can run linear regression with this new trnasformed array and build a new linear regression model\n",
    "u_model_nl_g.fit(poly_features2,uoutp_g) #New array and actual oupts were fitted by new model\n",
    "u_est_nl_g=model_nl_g.predict(poly_features2) #collection of model predictions\n",
    "\n",
    "u_est_nl_g\n",
    "print('MAE_NL_R:',mean_absolute_error(outp_g,est_nl_g)) #MAE values of model\n",
    "print('MSE_NL_R:',mean_squared_error(outp_g,est_nl_g)) #MSE values of model\n",
    "print('r2_NL_R:',r2_score(outp_g,est_nl_g)) #RSQ values of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7251d-efee-46a6-9a60-3ceff5e4bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_predict_r_all = r_f_m_r.predict(uinp)\n",
    "u_predict_r_all\n",
    "\n",
    "u_predict_g_all = r_f_m_g.predict(uinp)\n",
    "u_predict_g_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b56a4f-0ee7-4464-930b-ded6c5da1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importances_ function shows contribution of the variables in objective function. Since in random forest we do not have a such a simply equation like linear regression, this function shows us how variables affects the final prediction. (sort of coeeficint values) \n",
    "\n",
    "feature_importances_g=model_r_f_m_g.feature_importances_ # feature_importances_g is defined as a new output using feature_importances_ funcition in the end.\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "feature_importances_r=model_r_f_m_r.feature_importances_ # feature_importances_r is same only for grade\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "feature_importances_g #calling coeefient values in models for variables for grade\n",
    "feature_importances_r #calling coeefient values in models for variables for recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e07fe-334d-43f4-ac53-aa1ac0f498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_excel('SensGradeRF.xlsx', sheet_name='Tabelle1', header=0) #calling data from excel\n",
    "df3 #calling all the excel columns \n",
    "df3.describe() #decribtice statistic of data\n",
    "r1s=df[['R1']] #input 1\n",
    "r2s=df[['R2']] #input 2\n",
    "r3s=df[['R3']] #input 3\n",
    "ts=df[['Time']] #input 4\n",
    "\n",
    "inps=df3[['R1', 'R2', 'R3', 'Time']] #inputs were merged and identified as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf63277-702e-4fbe-8200-30601991baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here for collectig prediction from existed model with new dataset (unseen data)\n",
    "s_predict_g_all = r_f_m_g.predict(inps)\n",
    "s_predict_g_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
